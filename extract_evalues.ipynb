{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file (replace 'your_file.csv' with your actual file path)\n",
    "df_matrix = pd.read_csv(\"/home/labs/straussman/tatianas/Methylation_validation/Final_presence_absence_with_acessions_corrected_manually_DH_and_Tatiana.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583fd6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d4a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_excel(\"All_results_v2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e347ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (40, 43)\n",
      "Results shape: (3897, 7)\n",
      "=== Done ===\n",
      "Checked: 493\n",
      "Matched: 434\n",
      "Unmatched: 59\n",
      "Saved updated matrix to: updated_matrix_with_evalues_v3.csv\n",
      "Unmatched records saved to: unmatched_seq_hmm_v3.csv\n"
     ]
    }
   ],
   "source": [
    "#This code worked onto chatgpt:\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === 1. Load input files ===\n",
    "matrix_path = \"Final_presence_absence_with_acessions_corrected_manually_DH_and_Tatiana.csv\"\n",
    "results_path = \"All_results_v2.xlsx\"\n",
    "\n",
    "df_matrix = pd.read_csv(matrix_path)\n",
    "df_results = pd.read_excel(results_path)\n",
    "\n",
    "print(\"Matrix shape:\", df_matrix.shape)\n",
    "print(\"Results shape:\", df_results.shape)\n",
    "\n",
    "\n",
    "# === 2. Helpers to normalize IDs and HMM names ===\n",
    "def normalize_seq_id(seq_id):\n",
    "    \"\"\"\n",
    "    Normalize Sequence IDs to allow flexible matching.\n",
    "    Handles UniProt-like IDs, metaeuk contig names, etc.\n",
    "    \"\"\"\n",
    "    if pd.isna(seq_id) or seq_id == \"no\":\n",
    "        return []\n",
    "    \n",
    "    # Split if multiple IDs are stored together\n",
    "    parts = re.split(r\"[|:/\\s]+\", str(seq_id).strip())\n",
    "    \n",
    "    tokens = []\n",
    "    for p in parts:\n",
    "        # remove trailing \".1\", \".2\", etc.\n",
    "        p = re.sub(r\"\\.\\d+$\", \"\", p)\n",
    "        if p:\n",
    "            tokens.append(p)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def normalize_hmm_name(hmm):\n",
    "    \"\"\"Make HMM names consistent between files.\"\"\"\n",
    "    return re.sub(r\"[^A-Za-z0-9]+\", \"_\", str(hmm).strip().lower())\n",
    "\n",
    "\n",
    "# === 3. Prepare df_results lookup ===\n",
    "df_results[\"norm_seq_tokens\"] = df_results[\"Sequence_ID\"].apply(normalize_seq_id)\n",
    "df_results[\"norm_hmm\"] = df_results[\"HMM_used\"].apply(normalize_hmm_name)\n",
    "\n",
    "\n",
    "# === 4. Build dictionary for fast lookup ===\n",
    "lookup = {}\n",
    "for idx, row in df_results.iterrows():\n",
    "    hmm = row[\"norm_hmm\"]\n",
    "    evalue = row[\"E-value\"]\n",
    "    for token in row[\"norm_seq_tokens\"]:\n",
    "        lookup.setdefault((token, hmm), []).append(evalue)\n",
    "\n",
    "\n",
    "# === 5. Identify HMM / E-value column pairs in matrix ===\n",
    "col_pairs = {}\n",
    "for i, col in enumerate(df_matrix.columns):\n",
    "    if col.startswith(\"E-value\"):\n",
    "        hmm_col = df_matrix.columns[i - 1]   # the HMM hit column is right before E-value\n",
    "        evalue_col = col\n",
    "        col_pairs[hmm_col] = evalue_col\n",
    "\n",
    "\n",
    "# === 6. Fill the E-values in df_matrix ===\n",
    "total_checked, matched, unmatched = 0, 0, 0\n",
    "unmatched_records = []\n",
    "\n",
    "for hmm_col, evalue_col in col_pairs.items():\n",
    "    hmm_name = normalize_hmm_name(hmm_col)\n",
    "    \n",
    "    for idx, row in df_matrix.iterrows():\n",
    "        seq_id = row[hmm_col]\n",
    "        if pd.isna(seq_id) or seq_id == \"no\":\n",
    "            continue\n",
    "        \n",
    "        total_checked += 1\n",
    "        tokens = normalize_seq_id(seq_id)\n",
    "        \n",
    "        # Collect all possible matches\n",
    "        candidate_evalues = []\n",
    "        for token in tokens:\n",
    "            candidate_evalues.extend(lookup.get((token, hmm_name), []))\n",
    "        \n",
    "        if candidate_evalues:\n",
    "            # choose the best (lowest) e-value\n",
    "            best_evalue = min(candidate_evalues, key=lambda x: float(x))\n",
    "            df_matrix.at[idx, evalue_col] = best_evalue\n",
    "            matched += 1\n",
    "        else:\n",
    "            unmatched += 1\n",
    "            unmatched_records.append((seq_id, hmm_col))\n",
    "\n",
    "\n",
    "# === 7. Save updated output ===\n",
    "out_path = \"updated_matrix_with_evalues_v4.csv\"\n",
    "unmatched_out = \"unmatched_seq_hmm_v4.csv\"\n",
    "\n",
    "df_matrix.to_csv(out_path, index=False)\n",
    "pd.DataFrame(unmatched_records, columns=[\"Sequence_ID\", \"HMM_col\"]).to_csv(unmatched_out, index=False)\n",
    "\n",
    "print(\"=== Done ===\")\n",
    "print(\"Checked:\", total_checked)\n",
    "print(\"Matched:\", matched)\n",
    "print(\"Unmatched:\", unmatched)\n",
    "print(\"Saved updated matrix to:\", out_path)\n",
    "print(\"Unmatched records saved to:\", unmatched_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
